# ğŸ”— DeFi Blockchain ETL Platform

A production-grade data engineering pipeline for real-time Ethereum data ingestion, transformation, quantitative risk modeling, and live visualization.

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Blockchain Data Sources                     â”‚
â”‚     (Ethereum RPC, The Graph, Alchemy)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ gRPC / WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Ingestion Layer (Kafka Producers)           â”‚
â”‚  â€¢ Block Producer  â€¢ TX Producer  â€¢ Event Log Producer  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ Kafka Topics
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ETL Transform Layer (Pandas + SQLGlot)        â”‚
â”‚   â€¢ ERC-20/ERC-721 Decoder  â€¢ DeFi Primitive Parser    â”‚
â”‚   â€¢ Cross-chain Normalizer  â€¢ Risk Feature Engineer     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Quantitative Models & Risk Engine              â”‚
â”‚  â€¢ Portfolio VaR/CVaR  â€¢ Impermanent Loss Model         â”‚
â”‚  â€¢ MEV Exposure Scoring  â€¢ Protocol Risk Heuristics     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Flask API + Interactive Showcase               â”‚
â”‚  â€¢ 4 live chart endpoints  â€¢ Self-contained HTML        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Tech Stack

| Layer | Technologies |
|-------|-------------|
| Streaming | Kafka, gRPC, WebSocket, web3.py |
| ETL | Python, Pandas, SQLGlot |
| Blockchain | EVM (Ethereum), ERC-20, ERC-721, ERC-1155 |
| Risk Models | VaR, CVaR, Impermanent Loss, MEV Scoring |
| API | Flask, Flask-CORS |
| Data Warehouse | PostgreSQL, BigQuery, Snowflake (SQLGlot dialect translation) |

## Project Structure

```
blockchain_etl/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ kafka_producer.py       # Kafka producer: blocks, txs, token transfer logs
â”‚   â”œâ”€â”€ transform/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ etl_pipeline.py         # ETL: Pandas transforms + SQLGlot dialect builder
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ risk_models.py          # VaR, CVaR, Impermanent Loss, MEV, Protocol Risk
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ server.py                   # Flask API server (4 endpoints)
â”‚   â””â”€â”€ data_service.py             # Calls real risk models & ETL pipeline
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.example.yaml         # RPC, Kafka, DB, dialect config template
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_etl_pipeline.py        # 38 pytest unit tests
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_pipeline.py             # Main entry point (live streaming)
â”‚   â””â”€â”€ backfill.py                 # Historical block backfill
â”œâ”€â”€ blockchain_etl_showcase.html    # Interactive project showcase (self-contained)
â””â”€â”€ requirements.txt
```

## Project Showcase

`blockchain_etl_showcase.html` is a self-contained interactive showcase â€” open directly in any browser or deploy to GitHub Pages / Render for a shareable URL.

Includes:
- Live pipeline architecture diagram
- Interactive file tree
- Full tech stack breakdown
- Tabbed code snippets (SQLGlot, VaR, Impermanent Loss, Kafka)
- Four live visualizations powered by the Flask API:
  - **Rolling VaR & CVaR** â€” 30-day historical simulation on a $1M ETH position
  - **Impermanent Loss Curve** â€” LP vs hold value across price ratios (Uniswap V2 AMM)
  - **MEV Risk Heatmap** â€” block-by-block MEV exposure scores
  - **Token Transfer Volume** â€” hourly ERC-20 and ERC-721 decoded from Kafka stream

- Four interactive data visualizations:
  - **Rolling VaR & CVaR** â€” 30-day historical simulation on a $1M ETH position
  - **Impermanent Loss Curve** â€” LP vs hold value across price ratios (Uniswap V2 AMM)
  - **MEV Risk Heatmap** â€” block-by-block MEV exposure scores
  - **Token Transfer Volume** â€” hourly ERC-20 and ERC-721 decoded from Kafka stream

## Quickstart

```bash
# 1. Create and activate virtual environment
python -m venv venv
venv\Scripts\activate          # Windows
source venv/bin/activate       # Mac/Linux

# 2. Install dependencies
pip install -r requirements.txt

# 3. Run tests
pytest tests/ -v               # 38/38 expected

# 4. Copy and configure
cp config/config.example.yaml config/config.yaml
# Edit config.yaml: set RPC_URL and KAFKA_BOOTSTRAP_SERVERS

# 5. Start the Flask API (powers the frontend visualizations)
python api/server.py
# Running at http://localhost:5000

# 6. Open the showcase
# Double-click blockchain_etl_showcase.html â€” charts load live from API

# 7. Run the live pipeline (requires RPC URL + Kafka)
python scripts/run_pipeline.py --network mainnet

# 8. Backfill historical blocks
python scripts/backfill.py --start-block 18000000 --end-block 18001000
```

## Deploying for a Live Resume Link

Push to GitHub, then deploy to [Render](https://render.com):

- **Build command:** `pip install -r requirements.txt`
- **Start command:** `python api/server.py`
- Update `const API` in `blockchain_etl_showcase.html` to your Render URL